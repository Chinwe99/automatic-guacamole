{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction Tree Learning: Exercise 2\n",
    "\n",
    "\n",
    "\n",
    "In this exercise, you will have  the chance to investigate the informative data from the same publication. \n",
    "\n",
    "To make this task  a bit more realistic, we have given  you the  original data. You will have to standardize the dat (as shown in the pre-processing lecture and previous exercises) potentially using the pipeline approach of sklearn. \n",
    "\n",
    "\n",
    "```\n",
    "'biomarkers_raw.csv'\n",
    "``` \n",
    "\n",
    "Contains those genomic biomarkers.\n",
    "\n",
    "Use Random Forests to establish, which  are the most informative features (attributs/variables/classifiers/ etc.)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt # plotting and visulisation\n",
    "import seaborn as sns # nicer (easier) visualisation\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.model_selection import LeaveOneOut, GridSearchCV, KFold, StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "\n",
    "# own mini- library\n",
    "import session_helpers\n",
    "import IPython.display\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading in the file and setting the first column to be the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "biomarkers_file_csv = 'biomarkers_raw.csv'\n",
    "\n",
    "df = pd.read_csv(biomarkers_file_csv)\n",
    "df = df.set_index(['Sample'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish, which are the numerical columns\n",
    "numeric_features = list(df.select_dtypes(float).columns)\n",
    "\n",
    "# scaling using  the pipeline appraoch\n",
    "numeric_transformer = Pipeline(steps=[('scaler', StandardScaler())])\n",
    "\n",
    "# put the preprocessor together:\n",
    "preprocessor = ColumnTransformer(transformers=[ ('num',numeric_transformer,numeric_features), ])\n",
    "clf = Pipeline(steps=[('preprocessor', preprocessor)])\n",
    "\n",
    "# create a new dataframe, using the same names and indeces as in df_p\n",
    "df_norm = pd.DataFrame(clf.fit_transform(df[numeric_features]),columns=numeric_features,index=df.index)\n",
    "\n",
    "# add 'response' back into the new dataframe as 'target' and directly do the mapping\n",
    "target_mapper            = {\n",
    "                             #'C.':'negative',\n",
    "                             #'C.R.':'negative',\n",
    "                             'Low':'negative',\n",
    "                             'Int. I.':'negative',\n",
    "                             'Int. II.':'negative',\n",
    "                             'Int. II. R.':'negative',\n",
    "                             'High':'positive',\n",
    "                             'High R.':'positive',\n",
    "                            }\n",
    "\n",
    "target_mapper_multiclass = {\n",
    "                             'C.':'C.',\n",
    "                             'C. R.':'C. R.',\n",
    "                             'Low':'Low',\n",
    "                             'Int. I.':'Int. I.',\n",
    "                             'Int. II.':'Int. II.',\n",
    "                             'Int. II. R.':'Int. II. R.',\n",
    "                             'High':'High',\n",
    "                             'High R.':'High R.',\n",
    "                            }\n",
    "\n",
    "df_norm['target'] = df['Response'].map(target_mapper_multiclass)\n",
    "\n",
    "\n",
    "# drop entries, which do not have a class label (this results in not mapping it to any new target class)\n",
    "# if filter on the column 'target', looking for entries which are None or NaN\n",
    "df_norm = df_norm[df_norm['target'].notna()]\n",
    "\n",
    "# to be deleted\n",
    "#df_norm['Response'] = df['Response']#.map(target_mapper)\n",
    "#df_norm[['Response']+numeric_features].to_csv('clinical_biomarkers_new.csv')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For consistency\n",
    "\n",
    "we use X for the data vector and y for the target column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target column\n",
    "y = df_norm['target']\n",
    "# this drops the column 'target' for the dataframe and stores it in X\n",
    "X = df_norm.drop(['target'],axis=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the values of all columns\n",
    "\n",
    "Here we use the melt function of pandas. This function allows the values to be plotted in a nice fashion. Just click on Run and see. \n",
    "\n",
    "Are you able to spot an attribute or two, separating positive from negative?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data_melt = pd.melt(df_norm,id_vars='target',\n",
    "                    var_name='features',\n",
    "                    value_name='value')\n",
    "plt.figure(figsize=(60,10))\n",
    "ax = sns.boxplot(x='features', y='value', hue='target', data=plot_data_melt)\n",
    "ticks_information = plt.xticks(rotation=65)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier\n",
    "\n",
    "Now, establish the feature importance using a grid search and Random Forests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "#    'criterion': ['gini','entropy'], \n",
    "    'n_estimators': [2,3,5,10], \n",
    "    'max_depth':[1,2,3,4,5],\n",
    "    'min_samples_leaf':[2,5,7,10],\n",
    "}\n",
    "\n",
    "random_f_model = RandomForestClassifier() \n",
    "\n",
    "# possible values for scoring:\n",
    "# \n",
    "\n",
    "rf_grid_search = GridSearchCV(random_f_model, parameters, cv=5,scoring='roc_auc_ovo') \n",
    "grid_search = rf_grid_search.fit(X, y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_random_f_model = rf_grid_search.best_estimator_ # best model according to grid search \n",
    "\n",
    "best_random_f_model.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using dataframes\n",
    "df_importance = pd.DataFrame(list(zip(X.columns.values,best_random_f_model.feature_importances_)),columns=['column_name','feature_importance'])\n",
    "df_importance = df_importance.set_index(['column_name'])\n",
    "df_importance.sort_values(['feature_importance'],ascending=False,inplace=True)\n",
    "\n",
    "df_importance[df_importance['feature_importance']>0.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "\n",
    "sns.barplot(x='column_name',y='feature_importance',data=df_importance.reset_index(),palette='muted')\n",
    "ticks_information = plt.xticks(rotation=65)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
